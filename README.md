# MLX-LM API

A production-ready OpenAI-compatible API server for Apple MLX models with full audio capabilities and Streamlit ChatGPT clone.

## Features

- ğŸš€ **FastAPI Backend** - OpenAI-compatible endpoints
- ğŸ¤– **Streamlit ChatGPT Clone** - Full-featured chat interface
- ğŸµ **Audio Integration** - Speech-to-text and text-to-speech
- ğŸ—ï¸ **Clean Architecture** - Modular, scalable design
- ğŸ”§ **Dynamic Models** - Auto-discovery and switching
- ğŸ“š **Complete Documentation** - API docs and examples
- ğŸ¥ **Production Ready** - Health checks, logging, middleware

## Project Structure

```
mlx-llm-api/
â”œâ”€â”€ backend/               # FastAPI backend
â”‚   â”œâ”€â”€ app/               # Core application
â”‚   â”‚   â”œâ”€â”€ api/endpoints/ # Individual API endpoints
â”‚   â”‚   â”œâ”€â”€ core/          # Core functionality
â”‚   â”‚   â”œâ”€â”€ services/      # Business logic
â”‚   â”‚   â””â”€â”€ ...            # Config, models, etc.
â”‚   â””â”€â”€ main.py            # Backend entry point
â”œâ”€â”€ streamlit_app.py       # ChatGPT clone
â”œâ”€â”€ frontend/              # Additional frontend
â””â”€â”€ ...                    # Config and docs
```

## Quick Start

### 1. Install Dependencies
```bash
# Using uv (recommended)
uv sync

# Or using pip
pip install -e .
```

### 2. Configure Environment
```bash
cp env.example .env
# Edit .env with your model directory path
```

### 3. Start Backend API
```bash
cd backend && python main.py
```

### 4. Launch Streamlit App (Optional)
```bash
streamlit run streamlit_app.py
```

## Access Points

- **API Server**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs (development only)
- **Streamlit App**: http://localhost:8501
- **Health Check**: http://localhost:8000/api/health

## OpenAI-Compatible Endpoints

### Core API
- **Chat Completions**: `POST /v1/chat/completions`
- **Text Completions**: `POST /v1/completions`
- **Embeddings**: `POST /v1/embeddings`
- **Models**: `GET /v1/models`, `GET /v1/models/{id}`

### Audio API
- **Transcriptions**: `POST /v1/audio/transcriptions`
- **Translations**: `POST /v1/audio/translations`
- **Text-to-Speech**: `POST /v1/audio/speech`

### Management
- **Health Check**: `GET /api/health`
- **Model Management**: `POST /api/load-model`, `GET /api/models`

## Example Usage

```bash
# Chat with your MLX model
curl -X POST "http://localhost:8000/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "your-mlx-model",
    "messages": [{"role": "user", "content": "Hello!"}],
    "max_tokens": 100
  }'

# Transcribe audio
curl -X POST "http://localhost:8000/v1/audio/transcriptions" \
  -F "file=@audio.mp3" \
  -F "model=whisper-large-v3"

# Generate speech
curl -X POST "http://localhost:8000/v1/audio/speech" \
  -H "Content-Type: application/json" \
  -d '{"model": "kitten-tts-nano", "input": "Hello world!", "voice": "expr-voice-2-f"}' \
  --output speech.wav
```

## Streamlit ChatGPT Clone

The included Streamlit app provides a complete ChatGPT alternative with:

- ğŸ’¬ **Real-time chat** with your MLX models
- ğŸ¤ **Voice recording** and transcription
- ğŸ”Š **Text-to-speech** responses
- âš™ï¸ **Model selection** and parameter control
- ğŸ’¾ **Chat export** and history management

Launch with: `streamlit run streamlit_app.py`

## Documentation

See [CLAUDE.md](CLAUDE.md) for complete documentation including:
- Detailed API examples in Python, JavaScript, and cURL
- Architecture overview and design decisions
- OpenAI library compatibility guide
- Audio features and configuration
- Production deployment guidelines

## License

MIT License
